{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Langchain for building language models and chains\n",
        "# Install BeautifulSoup4 for parsing HTML and web scraping\n",
        "# Install pandas for data manipulation and analysis\n",
        "# Install pyarrow for reading and writing Parquet files\n",
        "# Install requests to make HTTP requests to fetch data from URLs\n",
        "!pip install langchain beautifulsoup4 pandas pyarrow requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hMy0An63_2X",
        "outputId": "d071a376-40c6-4b35-90e3-a1823c5a77cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (17.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "# URL of the Brainlox technical courses page\n",
        "url = \"https://brainlox.com/courses/category/technical\"\n",
        "\n",
        "# Load data from the webpage using Langchain's WebBaseLoader\n",
        "# This will fetch the content of the provided URL\n",
        "loader = WebBaseLoader(url)\n",
        "documents = loader.load()\n",
        "\n",
        "# Print extracted text\n",
        "# Displaying the first 500 characters of each document to inspect the content\n",
        "for doc in documents:\n",
        "    print(doc.page_content[:500])  # Printing first 500 characters"
      ],
      "metadata": {
        "id": "V-3_McAm7o_m",
        "outputId": "b6fbfa2d-e488-48b5-bc3c-57d8a2e18289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.16)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.32)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brainlox: Learn technical courses.Courses TechnicalAcademicLanguageMusicLifestyleBook a Free Demo NowSign InFAQContact UsPractice PythonLearn NowHomeCoursesCoursesWe found great courses available for you$30per sessionLEARN SCRATCH PROGRAMING\n",
            "Scratch Course is the foundation of coding and is a building block of a coding journey. If you want 16 LessonsView Details$30per sessionLEARN CLOUD COMPUTING BASICS-AWS\n",
            "In this course we are going to cover the basics and the most important services on AWS,\n",
            "A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import pandas as pd\n",
        "\n",
        "# Loading the Brainlox Technical Courses Page from the given URL\n",
        "# This fetches the content of the webpage using Langchain's WebBaseLoader\n",
        "url = \"https://brainlox.com/courses/category/technical\"\n",
        "loader = WebBaseLoader(url)\n",
        "documents = loader.load()\n",
        "\n",
        "# Extracting raw text from the page content\n",
        "# Combining all page content into one long string for further processing\n",
        "raw_text = \" \".join([doc.page_content for doc in documents])\n",
        "\n",
        "# Spliting the raw text into smaller chunks (500 characters each, with 50 characters overlap)\n",
        "# This is done to manage large text and allow for better processing in chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_text(raw_text)\n",
        "\n",
        "# Converting the list of text chunks into a DataFrame for easier manipulation and storage\n",
        "# The DataFrame allows for better organization of the chunks\n",
        "textChunksDF = pd.DataFrame({\"chunks\": chunks})\n",
        "\n",
        "# Saving the DataFrame as a Parquet file for efficient storage and future use\n",
        "# Parquet is a columnar format, ideal for storing large datasets efficiently\n",
        "textChunksDF.to_parquet(\"pageChunksDataSet.parquet\", index=False)\n",
        "\n",
        "print(\" Data saved successfully as 'pageChunksDataSet.parquet'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjbvfjmlTYFk",
        "outputId": "0124bbfe-c8af-46a3-e0c8-023a38d8eb0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Data saved successfully as 'pageChunksDataSet.parquet'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the transformers library for using pre-trained language models like GPT and BERT\n",
        "!pip install transformers\n",
        "\n",
        "# Installing torch, which is the deep learning framework needed for working with models in transformers\n",
        "!pip install torch\n",
        "\n",
        "# Installing bitsandbytes for quantization, which helps reduce the memory usage of large models\n",
        "!pip install bitsandbytes\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# This is the file where the website content has been split into smaller chunks\n",
        "textChunksDF = pd.read_parquet(\"pageChunksDataSet.parquet\")\n",
        "\n",
        "\n",
        "# This model will convert text into numerical representations (embeddings) for comparison\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # Use an efficient model for embeddings\n",
        "\n",
        "# Creating embeddings for the chunks\n",
        "# Convering each chunk of text into a numerical vector for similarity comparison\n",
        "chunks_embeddings = embedding_model.encode(textChunksDF['chunks'].tolist())\n",
        "\n",
        "# Creating a function to find the most relevant chunk based on user input\n",
        "def find_relevant_chunk(query):\n",
        "    # Converting the user's query into an embedding\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "\n",
        "    # Calculate the cosine similarity between the query and each chunk\n",
        "\n",
        "    similarities = cosine_similarity(query_embedding, chunks_embeddings)\n",
        "\n",
        "    # Get the index of the most similar chunk\n",
        "    most_similar_idx = np.argmax(similarities)\n",
        "\n",
        "    # Return the most similar chunk from the DataFrame\n",
        "    return textChunksDF['chunks'].iloc[most_similar_idx]\n",
        "\n",
        "# Loading a text generation pipeline from Hugging Face\n",
        "# This is used to generate text responses based on the retrieved relevant chunk\n",
        "text_generator = pipeline(\"text-generation\", model=\"gpt2\")  # Or any other model you prefer\n",
        "\n",
        "# Function to generate a response based on the relevant chunk\n",
        "def generate_response(query):\n",
        "\n",
        "    relevant_chunk = find_relevant_chunk(query)\n",
        "\n",
        "\n",
        "    # The response is generated using a text generation model\n",
        "    response = text_generator(relevant_chunk + \" \" + query, max_new_tokens=50, num_return_sequences=1)\n",
        "    return response[0]['generated_text']\n",
        "\n",
        "# Testing the chatbot with a sample query\n",
        "query = \"Tell me about technical courses in AI.\"\n",
        "response = generate_response(query)\n",
        "print(f\"Chatbot Response: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He7VdHbCTcJ2",
        "outputId": "b406609b-d9ce-47f9-ad62-60c8f3147e4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.61)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
            "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.0->bitsandbytes) (12.8.61)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.0->bitsandbytes) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Response: the fascinating world of Artif 5 LessonsView Details$30per sessionTime Mastery Camp: AI for Jobs, Business, CareersThe \"AI for Productivity and Time Management\" course: üöÄüí° Tell me about technical courses in AI. If you've attended the training I recommend using the following: A. The \"AI for Productivity and Time Management\" course: A course we recommend reading by someone like David Anderson: https://www.youtube.com/user/DavidAnderson/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Loading the saved Parquet file with text chunks\n",
        "textChunksDF = pd.read_parquet(\"pageChunksDataSet.parquet\")\n",
        "\n",
        "# Loading a pre-trained model for generating text embeddings\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # Use an efficient model for embeddings\n",
        "\n",
        "# Creating embeddings for the chunks\n",
        "chunks_embeddings = embedding_model.encode(textChunksDF['chunks'].tolist())\n",
        "\n",
        "# Creating a function to find the most relevant chunk based on user input\n",
        "def find_relevant_chunk(query):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "\n",
        "    # Calculating the cosine similarity between the query and each chunk\n",
        "    similarities = cosine_similarity(query_embedding, chunks_embeddings)\n",
        "\n",
        "    # Geting the index of the most similar chunk\n",
        "    most_similar_idx = np.argmax(similarities)\n",
        "\n",
        "    # Returning the most similar chunk\n",
        "    return textChunksDF['chunks'].iloc[most_similar_idx]\n",
        "\n",
        "# Load a text generation pipeline from Hugging Face\n",
        "text_generator = pipeline(\"text-generation\", model=\"gpt2\")  # Or any other model you prefer\n",
        "\n",
        "# Function to generate a response based on the relevant chunk\n",
        "def generate_response(query):\n",
        "    # Finding the most relevant chunk for the query\n",
        "    relevant_chunk = find_relevant_chunk(query)\n",
        "\n",
        "    # Using the relevant chunk to generate a response\n",
        "    response = text_generator(relevant_chunk + \" \" + query, max_new_tokens=50, num_return_sequences=1)\n",
        "    return response[0]['generated_text']\n",
        "\n",
        "# Testing the chatbot\n",
        "query = \"Tell me about technical courses in AI.\"\n",
        "response = generate_response(query)\n",
        "print(f\"Chatbot Response: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5BeiHpJTgVy",
        "outputId": "0a0ffaaf-c3eb-4d48-c81d-3fc02d15ef6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Response: the fascinating world of Artif 5 LessonsView Details$30per sessionTime Mastery Camp: AI for Jobs, Business, CareersThe \"AI for Productivity and Time Management\" course: üöÄüí° Tell me about technical courses in AI. You get to know algorithms and their problems better than humans. öÄüí° Tell me about Artificial Intelligence and how it may help you to understand your clients. You'll learn the ins and outs of real systems\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Loading the saved Parquet file with text chunks\n",
        "# This loads the Parquet file that contains the chunked text data from the previous steps\n",
        "textChunksDF = pd.read_parquet(\"pageChunksDataSet.parquet\")\n",
        "\n",
        "# Displaying all rows in the DataFrame\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# This will print all the rows in the DataFrame to the console for inspection or further analysis\n",
        "print(textChunksDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0XVfpfrT0c8",
        "outputId": "453c3e3d-8e22-4e1b-f33f-0ed344f9e354"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               chunks\n",
            "0   Brainlox: Learn technical courses.Courses Tech...\n",
            "1   At the end  20 LessonsView Details$30per sessi...\n",
            "2   You can open all kinds of doors for advancemen...\n",
            "3   This introduction to cloud computing on Amazon...\n",
            "4   Take your python skills to the next level and ...\n",
            "5   Python is a language with simple syntax, and a...\n",
            "6   Learners will be taught the 16 LessonsView Det...\n",
            "7   Create a Hangman GamePython Playground : Creat...\n",
            "8   the fascinating world of Artif 5 LessonsView D...\n",
            "9   Day 1: Introduction to AI and its Applica 11 L...\n",
            "10  Build Business SuccessWelcome to the world of ...\n",
            "11  five days, campers will delve in 5 LessonsView...\n",
            "12    1: Introduction to Java and Programming Basics.\n",
            "13  2. 8 LessonsView Details$30per sessionChatbot ...\n",
            "14  Playground\" camp where coding meets creativity...\n",
            "15  Join our \"AI for Productivity and Time Managem...\n",
            "16  the fundamentals, explore data ac 7 LessonsVie...\n",
            "17  Details$30per sessionScratch Playground: Creat...\n",
            "18  Unleash your creativity with cutting-edge AI t...\n",
            "19  sessionPython Playground: Create a Tic Tac Toe...\n",
            "20  with our engaging 7-day summer camp! Starting ...\n",
            "21  sessionSummer Bootcamp: 5-Day Scratch Programm...\n",
            "22  Analyzer using Python Bootcamp for Kids is an ...\n",
            "23  Details$30per sessionPython Playground: Create...\n",
            "24  With Artificial Intelligence! (For Kids)Dive i...\n",
            "25  Welcome to the \"Introduction to Python Game De...\n",
            "26  program designed to introduce y 8 LessonsView ...\n",
            "27  Learning: 7-Day Project-Based Summer CampJoin ...\n",
            "28  Lesson 2: Getting Started in Creative Mod 7 Le...\n",
            "29  Playground: Create a Space Game!Scratch Playgr...\n",
            "30  class is designed for complete beg 7 LessonsVi...\n",
            "31  Get ready to unlock the secrets of building in...\n",
            "32  education!ExploreHomeCoursesGift a CourseShare...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install flask  sentence-transformers faiss-cpu pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcQjoCboUET_",
        "outputId": "60c84820-38c4-4c46-8f7a-8f9af62bc69d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.8.61)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import os\n",
        "\n",
        "# Loading the saved Parquet file with text chunks\n",
        "textChunksDF = pd.read_parquet(\"pageChunksDataSet.parquet\")\n",
        "\n",
        "# Loading the pre-trained SentenceTransformer model for embedding\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Define the FAISS index file path\n",
        "faiss_index_file = \"faiss_index.bin\"\n",
        "\n",
        "# Checking if FAISS index exists, else create a new one\n",
        "if os.path.exists(faiss_index_file):\n",
        "    # Load existing FAISS index\n",
        "    faiss_index = faiss.read_index(faiss_index_file)\n",
        "    print(\"Loaded existing FAISS index.\")\n",
        "else:\n",
        "    # Creating embeddings for the chunks\n",
        "    chunks_embeddings = embedding_model.encode(textChunksDF['chunks'].tolist())\n",
        "\n",
        "    # Initializing FAISS index\n",
        "    dimension = chunks_embeddings.shape[1]  # The embedding dimension\n",
        "    faiss_index = faiss.IndexFlatL2(dimension)  # L2 distance (Euclidean)\n",
        "\n",
        "    # Adding embeddings to FAISS index\n",
        "    faiss_index.add(np.array(chunks_embeddings).astype(np.float32))\n",
        "\n",
        "    # Saving FAISS index to disk\n",
        "    faiss.write_index(faiss_index, faiss_index_file)\n",
        "    print(\"Created and saved new FAISS index.\")\n",
        "\n",
        "# Function to find the most relevant chunk\n",
        "def find_relevant_chunk(query):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    k = 1  # Get top 1 most similar chunk\n",
        "    _, indices = faiss_index.search(np.array(query_embedding).astype(np.float32), k)\n",
        "    most_similar_idx = indices[0][0]\n",
        "    return textChunksDF['chunks'].iloc[most_similar_idx]\n",
        "\n",
        "# Function to generate response\n",
        "def generate_response(query):\n",
        "    relevant_chunk = find_relevant_chunk(query)\n",
        "    return relevant_chunk  # You can integrate a text generation model if needed\n",
        "\n",
        "# Testing the chatbot\n",
        "query = \"Tell me about technical courses in AI.\"\n",
        "response = generate_response(query)\n",
        "print(f\"Chatbot Response: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ7R932PT586",
        "outputId": "6c716743-fba4-4e74-f57a-697775f6da8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded existing FAISS index.\n",
            "Chatbot Response: the fascinating world of Artif 5 LessonsView Details$30per sessionTime Mastery Camp: AI for Jobs, Business, CareersThe \"AI for Productivity and Time Management\" course: üöÄüí°\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import os\n",
        "\n",
        "# Loading the saved Parquet file with text chunks\n",
        "textChunksDF = pd.read_parquet(\"pageChunksDataSet.parquet\")\n",
        "\n",
        "# Loading the pre-trained SentenceTransformer model for embedding\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Define the FAISS index file path\n",
        "faiss_index_file = \"faiss_index.bin\"\n",
        "\n",
        "# Checking if FAISS index exists, else create a new one\n",
        "if os.path.exists(faiss_index_file):\n",
        "    # Load existing FAISS index\n",
        "    faiss_index = faiss.read_index(faiss_index_file)\n",
        "    print(\"Loaded existing FAISS index.\")\n",
        "else:\n",
        "    # Creating embeddings for the chunks\n",
        "    chunks_embeddings = embedding_model.encode(textChunksDF['chunks'].tolist())\n",
        "\n",
        "    # Initializing FAISS index\n",
        "    dimension = chunks_embeddings.shape[1]  # The embedding dimension\n",
        "    faiss_index = faiss.IndexFlatL2(dimension)  # L2 distance (Euclidean)\n",
        "\n",
        "    # Adding embeddings to FAISS index\n",
        "    faiss_index.add(np.array(chunks_embeddings).astype(np.float32))\n",
        "\n",
        "    # Saving FAISS index to disk\n",
        "    faiss.write_index(faiss_index, faiss_index_file)\n",
        "    print(\"Created and saved new FAISS index.\")\n",
        "\n",
        "# Function to find the most relevant chunk\n",
        "def find_relevant_chunk(query):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    k = 1  # Get top 1 most similar chunk\n",
        "    _, indices = faiss_index.search(np.array(query_embedding).astype(np.float32), k)\n",
        "    most_similar_idx = indices[0][0]\n",
        "    return textChunksDF['chunks'].iloc[most_similar_idx]\n",
        "\n",
        "# Function to generate response\n",
        "def generate_response(query):\n",
        "    relevant_chunk = find_relevant_chunk(query)\n",
        "    return relevant_chunk  # You can integrate a text generation model if needed\n",
        "\n",
        "# Testing the chatbot\n",
        "query = \"Tell me about technical courses in AI.\"\n",
        "response = generate_response(query)\n",
        "print(f\"Chatbot Response: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX_j73a4UJv6",
        "outputId": "91b4f242-c7b3-42ef-f26b-2bd1ffa20449"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded existing FAISS index.\n",
            "Chatbot Response: the fascinating world of Artif 5 LessonsView Details$30per sessionTime Mastery Camp: AI for Jobs, Business, CareersThe \"AI for Productivity and Time Management\" course: üöÄüí°\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# Loading the saved Parquet file with text chunks\n",
        "textChunksDF = pd.read_parquet(\"pageChunksDataSet.parquet\")\n",
        "\n",
        "# Initializing SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Function to search for relevant chunks related to the query\n",
        "def searchKNearestMatchingDocuments(query: str, k: int = 3):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    # Creating embeddings for the text chunks\n",
        "    chunks_embeddings = embedding_model.encode(textChunksDF['chunks'].tolist())\n",
        "    # Initializing FAISS index and add the embeddings\n",
        "    dimension = chunks_embeddings.shape[1]\n",
        "    faiss_index = faiss.IndexFlatL2(dimension)\n",
        "    faiss_index.add(np.array(chunks_embeddings).astype(np.float32))\n",
        "    _, indices = faiss_index.search(np.array(query_embedding).astype(np.float32), k)\n",
        "    retrieved_chunks = textChunksDF['chunks'].iloc[indices[0]].tolist()\n",
        "    return retrieved_chunks\n",
        "\n",
        "# Function to format the query with the retrieved documents\n",
        "def transformQuery(query: str, contextualDocs: list[str]):\n",
        "    formatted_query = '''You are an assistant for answering questions.\n",
        "You are given extracted parts of a long document and a question. Provide a conversational answer. If you don't know the answer, just say \"I do not know.\" Don’t make up an answer.'''\n",
        "    formatted_query += \"\\n\\nQuestion: \" + query\n",
        "    formatted_query += \"\\n\\nDocument Chunks: \\n\" + \"\\n\".join(contextualDocs)\n",
        "    return formatted_query\n",
        "\n",
        "# Function to generate a response using a language model\n",
        "def getllmResponse(prompt):\n",
        "    # Checking if the input prompt exceeds the token limit\n",
        "    max_input_length = 1024\n",
        "    if len(prompt.split()) > max_input_length:\n",
        "\n",
        "        prompt_chunks = [prompt[i:i+max_input_length] for i in range(0, len(prompt), max_input_length)]\n",
        "        responses = [text_generator(chunk) for chunk in prompt_chunks]\n",
        "        return \" \".join([response[0][\"generated_text\"] for response in responses])  # Combine the responses\n",
        "    else:\n",
        "        sequences = text_generator(prompt, max_new_tokens=200)  # Generate a response with max new tokens (adjust as needed)\n",
        "        return sequences[0][\"generated_text\"]\n",
        "\n",
        "# Example queries to be used\n",
        "queries = [\n",
        "    \"What is the 'Introduction to Cloud Computing' course about?\",\n",
        "    \"Tell me about the 'AI for Productivity' course.\",\n",
        "    \"What will I learn in the 'Python Playground' course?\",\n",
        "    \"How many lessons are in the 'Python Game Development' course?\",\n",
        "    \"How long does the 'Build Business Success' course last?\",\n",
        "    \"What is the cost of the 'Introduction to Java and Programming Basics' course?\",\n",
        "    \"What are the target audience for the 'AI for Kids' course?\",\n",
        "    \"What will I learn in the 'Python Playground: Create a Tic Tac Toe Game' course?\"\n",
        "]\n",
        "\n",
        "# Iterating through queries and process\n",
        "for query in queries:\n",
        "    print(\"\\nQuestion:\")\n",
        "    print(query)\n",
        "\n",
        "    # Searching for relevant chunks related to the query\n",
        "    retrievedPages = searchKNearestMatchingDocuments(query, k=2)  # Get the relevant chunks\n",
        "\n",
        "    # Formating the query with the retrieved documents\n",
        "    modified_rag_prompt = transformQuery(query, retrievedPages)\n",
        "\n",
        "    # Geting the response from the language model\n",
        "    response = getllmResponse(modified_rag_prompt)\n",
        "\n",
        "    # Printing the response with clear separation\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"Answer:\")\n",
        "    print(response)\n",
        "    print(\"\\n\" + \"-\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK7ReR1Zhg-6",
        "outputId": "3e12c434-57e4-455e-ced5-b65b301322be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question:\n",
            "What is the 'Introduction to Cloud Computing' course about?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Answer:\n",
            "You are an assistant for answering questions.\n",
            "You are given extracted parts of a long document and a question. Provide a conversational answer. If you don't know the answer, just say \"I do not know.\" Don’t make up an answer.\n",
            "\n",
            "Question: What is the 'Introduction to Cloud Computing' course about?\n",
            "\n",
            "Document Chunks: \n",
            "This introduction to cloud computing on Amazon AWS course takes you from the AWS Ad 18 LessonsView Details$30per sessionPYTHON PROGRAMMING-BEGINNER\n",
            "Python is a language with simple syntax, and a powerful set of libraries. It has a rich programming 16 LessonsView Details$30per sessionRoblox Programming For BeginnersExplore the dynamic universe of game development with our \"Roblox Game Development Fundamentals\" cou 15 LessonsView Details$32per sessionPYTHON PROGRAMMING-INTERMEDIATE\n",
            "Brainlox: Learn technical courses.Courses TechnicalAcademicLanguageMusicLifestyleBook a Free Demo NowSign InFAQContact UsPractice PythonLearn NowHomeCoursesCoursesWe found great courses available for you$30per sessionLEARN SCRATCH PROGRAMING\n",
            "Scratch Course is the foundation of coding and is a building block of a coding journey. If you want 16 LessonsView Details$30per sessionLEARN CLOUD COMPUTING BASICS-AWS\n",
            "In this course we are going to cover the basics and the most important services on AWS, the basics of the language and basic tools to help developers build amazing applications for AWS!This course is for novice and experienced people. The lessons are a mix of lessons on each application that you learn to run your applications and also a video about how to do this.If you are looking for help with coding this course, try our free tutorial on setting up a free AWS account or just for fun, start with us: AWS.com/Cheat - Learn programming languages from our Community Manager here:http://community.cloudbase.com/accounts/enroll/community-manager/swift-learning-learns-programming-programming-to-across-the-cloud/\n",
            "\n",
            "We have partnered with Google to make this course available for everyone. If you like our programs, this course also appears as part of our Amazon.com Partner Program to help make this course even more popular and free.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Question:\n",
            "Tell me about the 'AI for Productivity' course.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Answer:\n",
            "You are an assistant for answering questions.\n",
            "You are given extracted parts of a long document and a question. Provide a conversational answer. If you don't know the answer, just say \"I do not know.\" Don’t make up an answer.\n",
            "\n",
            "Question: Tell me about the 'AI for Productivity' course.\n",
            "\n",
            "Document Chunks: \n",
            "the fascinating world of Artif 5 LessonsView Details$30per sessionTime Mastery Camp: AI for Jobs, Business, CareersThe \"AI for Productivity and Time Management\" course: üöÄüí°\n",
            "Join our \"AI for Productivity and Time Management\" course and lea 11 LessonsView Details$30per sessionSummer Bootcamp with JavaScript: Real Projects, Real ResultsIn this 5-day camp, you'll dive headfirst into JavaScript, one of the world's most popular programmi 5 LessonsView Details$30per sessionAI Disruption: Top Entrepreneurs Harnessing AI for Unprecedented Success! (For Kids)Understand the role and potential of AI in entrepreneurship, learn the fundamentals, explore data ac 7 LessonsView Details$32 per sessionSummer Bootcamp for Real Productivity: What is the difference between AI for your business job and an employee's job? Find out!Join our \"AI for Productivity and Time Management\" course and lea 10 LessonsView Details$32per session\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Question:\n",
            "What will I learn in the 'Python Playground' course?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Answer:\n",
            "You are an assistant for answering questions.\n",
            "You are given extracted parts of a long document and a question. Provide a conversational answer. If you don't know the answer, just say \"I do not know.\" Don’t make up an answer.\n",
            "\n",
            "Question: What will I learn in the 'Python Playground' course?\n",
            "\n",
            "Document Chunks: \n",
            "Python is a language with simple syntax, and a powerful set of libraries. It has a rich programming 16 LessonsView Details$35per sessionAdvanced Roblox Scripting Workshop\"Are you ready to unlock the full potential of your Roblox game development skills? Join our Interme 14 LessonsView Details$30per sessionRobotics Adventure Awaits:Join Our Summer Camp for Young Tech Wizards!This course is designed to introduce beginners to the world of robotics. Learners will be taught the 16 LessonsView\n",
            "Take your python skills to the next level and start building real applications.\n",
            "Python is a pro 16 LessonsView Details$35per sessionPYTHON PROGRAMMING-ADVANCEIf you already know Python basics, then this training is the next step in your Python learning path  30 LessonsView Details$30per sessionPYTHON PROGRAMMING GROUP CLASSES - BEGINNER - PREVIEW OF THE NEW PLAYGROUND The Python Studio team is constantly seeking new teaching opportunities. It is our goal to provide you with the highest level of Python training for your Python programming skills. We encourage you to join our Intermyon 11 LessonsView Details$30per sessionPYTHON PROGRAMMING PARTNERING- BEGINNER - PREVIEW OF THE NEW PLAYGROUND The PyPy Group Learning Group is a great opportunity for new to Python and is a group of over 4,000 students that share unique interests. Our goal is to improve your Python programming skills and also teach you the tools and tools used to build great software. We want you to develop an understanding of Python programming using an intuitive, common-sense and well-rounded approach to Python. If you are an Intermyon Community member, we are interested in hiring you to help us with this part of the project. We offer a wide variety of Python programming courses, ranging from beginner to advanced. PyPy 3\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Question:\n",
            "How many lessons are in the 'Python Game Development' course?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Answer:\n",
            "You are an assistant for answering questions.\n",
            "You are given extracted parts of a long document and a question. Provide a conversational answer. If you don't know the answer, just say \"I do not know.\" Don’t make up an answer.\n",
            "\n",
            "Question: How many lessons are in the 'Python Game Development' course?\n",
            "\n",
            "Document Chunks: \n",
            "Python is a language with simple syntax, and a powerful set of libraries. It has a rich programming 16 LessonsView Details$35per sessionAdvanced Roblox Scripting Workshop\"Are you ready to unlock the full potential of your Roblox game development skills? Join our Interme 14 LessonsView Details$30per sessionRobotics Adventure Awaits:Join Our Summer Camp for Young Tech Wizards!This course is designed to introduce beginners to the world of robotics. Learners will be taught the 16 LessonsView\n",
            "Take your python skills to the next level and start building real applications.\n",
            "Python is a pro 16 LessonsView Details$35per sessionPYTHON PROGRAMMING-ADVANCEIf you already know Python basics, then this training is the next step in your Python learning path  30 LessonsView Details$30per sessionPYTHON PROGRAMMING GROUP CLASSES - BEGINNER's Guide to the Practical Introduction to Pyramid ProgrammingLearn and Practice the 5th Part of the 3-Step Programming Tutorial on this Course, 1st, to 3rd, with a 5th part in the 3-Lesson Workshop on this Course, with the 3-Lesson Workshop - BEGINNER's Guide to the Practical Introduction to Pyramid Programming and the 2nd (with 3-Lesson) Session on this Course, the 5th and 8th (of any time).The Course contains 5 lessons - 1 of the Pyramids and Pyramids - and each lesson consists of an answer that you can use to learn and develop your Python game, as well as a quiz at all levels of the Python world. The Pyramids and Pyramids are a part of a series of 2-Lesson Session, both a Pyramids and a Pyramid, on what Pyramid-Developed Language (GnuPGP) will teach you about the Python-Sculptor. Pyramids\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Question:\n",
            "How long does the 'Build Business Success' course last?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Answer:\n",
            "You are an assistant for answering questions.\n",
            "You are given extracted parts of a long document and a question. Provide a conversational answer. If you don't know the answer, just say \"I do not know.\" Don’t make up an answer.\n",
            "\n",
            "Question: How long does the 'Build Business Success' course last?\n",
            "\n",
            "Document Chunks: \n",
            "Build Business SuccessWelcome to the world of AI in entrepreneurship!  In this course, we will embark on a thrilling journ 7 LessonsView Details$30per sessionChatGPT Boot Camp: Basics & Best UsesJoin us for an exciting journey into the world of AI chatbots with this 5-day bootcamp. You'll learn 5 LessonsView Details$30per sessionCreate-A-Bot: A Project-Based Robotics ExplorationIgnite your child's tech curiosity with our \"RoboRacers\" camp! Over five days, campers will delve in 5 LessonsView\n",
            "Join our \"AI for Productivity and Time Management\" course and lea 11 LessonsView Details$30per sessionSummer Bootcamp with JavaScript: Real Projects, Real ResultsIn this 5-day camp, you'll dive headfirst into JavaScript, one of the world's most popular programmi 5 LessonsView Details$30per sessionAI Disruption: Top Entrepreneurs Harnessing AI for Unprecedented Success! (For Kids)Understand the role and potential of AI in entrepreneurship, learn the fundamentals, explore data ac 7 LessonsView Details$30per sessionHow does your project become self-sustaining?In this training, we will explore the principles that enabled all of your projects to thrive. Learn how you organize, build, and manage your teams and create solutions to problem 4 in 5 lessonsview details\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Question:\n",
            "What is the cost of the 'Introduction to Java and Programming Basics' course?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Answer:\n",
            "You are an assistant for answering questions.\n",
            "You are given extracted parts of a long document and a question. Provide a conversational answer. If you don't know the answer, just say \"I do not know.\" Don’t make up an answer.\n",
            "\n",
            "Question: What is the cost of the 'Introduction to Java and Programming Basics' course?\n",
            "\n",
            "Document Chunks: \n",
            "At the end  20 LessonsView Details$30per sessionLEARN MOBILE DEVELOPMENT\n",
            "Mobile application development is the process of creating software applications that run on a mobil 24 LessonsView Details$30per sessionLEARN CORE JAVA PROGRAMMING ONLINE\n",
            "Java is a very popular high-level, class-based, object-oriented programming language that is design 41 LessonsView Details$30per sessionLEARN ROBOTICS\n",
            "with our engaging 7-day summer camp! Starting from scratch, yo 7 LessonsView Details$30per sessionHands-on Java: Project-based Learning for Coding NovicesEmbark on a coding adventure with our \"Code, Create, Conquer\" Java camp! In just 7 days, kids will l 7 LessonsView Details$30per sessionPython Playground: Create a Memory GamePython Playground: Create a Memory Game is a beginner-level course designed for kids who are interes 8 LessonsView Details$30per sessionSummer Bootcamp: 5-Day Scratch Workshop by our Summer Bootcamp instructors! Summer Bootcamp takes 6 months and 6 weeks to complete! Summer Bootcamp is designed for all of us 3 LessonsView Details$30per sessionCultural Awareness: Cultural Awareness Training by all-inclusive Cultural Awareness Training for every student - Kids from all over the world, meet the cultural and community leaders who will help you learn new things! Community Awareness Training and Instruction, a 5-Day, 6-Day-6-City Camp For Our Local Friends (Kids in Los Angeles), gives you the tools to engage local leaders during their 6-day program! Caring Leadership Program (CALP): Caring Leadership Program is an international community of educators and community leaders working alongside educators, learners and visitors in various community centers 4 LessonsView Details$30per sessionCultural Awareness Training: Cultural Awareness - Youth Day Program by ALL-OWNINGCALP TOGETHER, the first of these 5-day-6-city programs - has been\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Question:\n",
            "What are the target audience for the 'AI for Kids' course?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Answer:\n",
            "You are an assistant for answering questions.\n",
            "You are given extracted parts of a long document and a question. Provide a conversational answer. If you don't know the answer, just say \"I do not know.\" Don’t make up an answer.\n",
            "\n",
            "Question: What are the target audience for the 'AI for Kids' course?\n",
            "\n",
            "Document Chunks: \n",
            "Playground\" camp where coding meets creativity! Kids will explor 7 LessonsView Details$30per sessionAI Secrets Revealed: Master Productivity Hacks That Will Blow Your Mind! (For Kids)Boost your productivity with AI!\n",
            "the fundamentals, explore data ac 7 LessonsView Details$30per sessionThe AI Writer's Masterclass: Innovation and Inspiration in Creative Writing! (For Kids)Enhance your creative writing skills with AI! Join our 10-day course and explore AI's role in writin 10 LessonsView Details$32per sessionWeb Development Pro: Intermediate LevelReady to unlock the full potential of web development? Join our \"Intermediate Web Development Master 8 LessonsView Details$30per sessionScratch Playground: Create a web application on your own platform. Explore more than 40 easy, powerful and free to use applications! We offer full support for iPhone®, iPad® and Android. Join our 12-hour course Learn How It's Made!Get Started on Your First Design Projects! (Download course)Explore the web & write online with your favorite app.Get to know our community!Join the \"Community of Apps\" program for learning about what you'll need to learn in order to build success.\n",
            "\n",
            "\n",
            "If You have any questions or comments, please contact our Support@AndroidAppEngadget line at 1-877-327-3834.\n",
            "\n",
            "\n",
            "Related Videos from The Next Generation of Learning Technology:\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Question:\n",
            "What will I learn in the 'Python Playground: Create a Tic Tac Toe Game' course?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Answer:\n",
            "You are an assistant for answering questions.\n",
            "You are given extracted parts of a long document and a question. Provide a conversational answer. If you don't know the answer, just say \"I do not know.\" Don’t make up an answer.\n",
            "\n",
            "Question: What will I learn in the 'Python Playground: Create a Tic Tac Toe Game' course?\n",
            "\n",
            "Document Chunks: \n",
            "Unleash your creativity with cutting-edge AI tec 10 LessonsView Details$30per sessionPython Playground: Create Your Own Snake GameThrough this course, participants will learn the fundamentals of Python programming language, as wel 8 LessonsView Details$30per sessionBuild your own Calculator using Python Bootcamp for kidsThis bootcamp is a fun and engaging program designed to introduce children to the basics of programm 8 LessonsView Details$30per sessionPython Playground: Create a Tic Tac Toe\n",
            "sessionPython Playground: Create a Tic Tac Toe GameAn interactive and hands-on tutorial designed to help learners build their programming skills while  8 LessonsView Details$30per sessionScratch Playground: Create a Flappy Bird Game!Scratch Playground 103: Create a Flappy Bird is a beginner to intermediate level course designed to  8 LessonsView Details$30per sessionHTML, CSS, JavaScript: 7-Day Summer BootcampJump into the vibrant world of coding with our engaging 7-day summer camp! Starting Aug. 2, students will receive their first lesson (0.7) of the 3 months of course. A 2 day course is one day on 8 different topics and is free! Learn something new today and be prepared! Scratch 7 days, Beginner to Advanced. You can enroll now to start your semester free! Register now and be prepared!\n",
            "\n",
            "Topic Name: Playground101\n",
            "\n",
            "Course Title: Designing a Flappy Bird Game\n",
            "\n",
            "Date Course (website): July 2014\n",
            "\n",
            "Author(s): Mark J. Wiederhein\n",
            "\n",
            "Course Prerequisites: 3rd grade, 1st and 2nd year of college\n",
            "\n",
            "Recommended Courses: \n",
            "\n",
            "Introduction to Programming from the ground up in this course (learn from a mentor)\n",
            "\n",
            "Designing a Flappy Bird Game based on the basic concepts of Mario 64: The Animation and Video Game\n",
            "\n",
            "Flappy Birds - A Beginner's Guide with tutorials and video tutorials based on the\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import os\n",
        "\n",
        "# Initializing Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Loading the saved Parquet file with text chunks\n",
        "textChunksDF = pd.read_parquet(\"pageChunksDataSet.parquet\")\n",
        "\n",
        "# Loading the pre-trained SentenceTransformer model for embedding\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Defining the FAISS index file path\n",
        "faiss_index_file = \"faiss_index.bin\"\n",
        "\n",
        "# Checking if FAISS index exists, else create a new one\n",
        "if os.path.exists(faiss_index_file):\n",
        "    # Load existing FAISS index\n",
        "    faiss_index = faiss.read_index(faiss_index_file)\n",
        "    print(\"Loaded existing FAISS index.\")\n",
        "else:\n",
        "    # Creating embeddings for the chunks\n",
        "    chunks_embeddings = embedding_model.encode(textChunksDF['chunks'].tolist())\n",
        "\n",
        "    # Initializing FAISS index\n",
        "    dimension = chunks_embeddings.shape[1]  # The embedding dimension\n",
        "    faiss_index = faiss.IndexFlatL2(dimension)  # L2 distance (Euclidean)\n",
        "\n",
        "    # Adding embeddings to FAISS index\n",
        "    faiss_index.add(np.array(chunks_embeddings).astype(np.float32))\n",
        "\n",
        "    # Saving FAISS index to disk\n",
        "    faiss.write_index(faiss_index, faiss_index_file)\n",
        "    print(\"Created and saved new FAISS index.\")\n",
        "\n",
        "# Function to find the most relevant chunk\n",
        "def find_relevant_chunk(query):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    k = 1  # Get top 1 most similar chunk\n",
        "    _, indices = faiss_index.search(np.array(query_embedding).astype(np.float32), k)\n",
        "    most_similar_idx = indices[0][0]\n",
        "    return textChunksDF['chunks'].iloc[most_similar_idx]\n",
        "\n",
        "@app.route(\"/chat\", methods=[\"POST\"])\n",
        "def chat():\n",
        "    data = request.get_json()\n",
        "    query = data.get(\"query\", \"\")\n",
        "    if not query:\n",
        "        return jsonify({\"error\": \"Query is required\"}), 400\n",
        "\n",
        "    relevant_chunk = find_relevant_chunk(query)\n",
        "    return jsonify({\"response\": relevant_chunk})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, port=5005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18hgArcGUQAa",
        "outputId": "25615921-28c1-48a5-f152-1244d422481d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded existing FAISS index.\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5005\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}